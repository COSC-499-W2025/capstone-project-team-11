#!/usr/bin/env python3
"""Generate a resume Markdown for a specified username from the database.

Usage:
  python3 src/generate_resume.py --username <github_username>

The script reads project data from the local database, aggregates project-level
facts, and writes `resumes/<username>_resume.md`.
"""
import argparse
import json
import os
import re
import sqlite3
import sys
from db import get_project_display_name, load_projects_for_generation
from cli_username_selection import (
    select_identity_from_projects,
    get_candidate_usernames,
)
from collections import defaultdict
from datetime import datetime
from textwrap import dedent
from db import save_resume
from project_evidence import get_project_id_by_name, get_evidence_for_project, format_evidence_for_resume
from config import load_config, save_config, config_path as default_config_path
from consent import ask_yes_no
from llm_summary import DEFAULT_MODEL, generate_resume_summary_text




def find_json_and_txt(root):
    matches = []
    for dirpath, dirs, files in os.walk(root):
        for f in files:
            if f.endswith('.json') or f.endswith('.txt'):
                matches.append(os.path.join(dirpath, f))
    return matches


def load_json(path):
    try:
        with open(path, 'r', encoding='utf-8') as fh:
            return json.load(fh)
    except Exception:
        return None


# Common acronym mappings to preserve casing in normalized names
ACRONYMS = {
    'tcp': 'TCP',
    'udp': 'UDP',
    'api': 'API',
    'sql': 'SQL',
    'html': 'HTML',
    'css': 'CSS',
    'json': 'JSON',
    'js': 'JS',
    'r': 'R',
    'c#': 'C#',
    'c++': 'C++',
    'go': 'Go',
    'java': 'Java',
    'kotlin': 'Kotlin',
    'typescript': 'TypeScript',
    'django': 'Django',
    'fastapi': 'FastAPI',
    'flask': 'Flask'
}


def normalize_project_name(name, path=None):
    """Normalize project name for resume output.

    - Removes common autogenerated suffixes like `_info_YYYY...` or `_summary_...`
    - Replaces separators (-, _, ., /) with spaces
    - Capitalizes words while preserving known acronyms
    """
    if not name and path:
        name = os.path.basename(path)
    if not name:
        return ''

    s = str(name)
    # strip common autogenerated suffixes
    s = re.sub(r'(_info[_-].*|_summary[_-].*|_info.*|_summary.*)$', '', s, flags=re.IGNORECASE)
    # replace separators with spaces
    s = re.sub(r'[\._/]+', ' ', s)
    s = s.replace('-', ' ')
    s = s.replace('__', ' ')
    s = s.strip()

    tokens = s.split()
    out_tokens = []
    for tok in tokens:
        tl = tok.lower()
        if tl in ACRONYMS:
            out_tokens.append(ACRONYMS[tl])
        else:
            # preserve camelCase/TitleCase if present, else capitalize
            if re.search(r'[A-Z]', tok[1:]):
                out_tokens.append(tok)
            else:
                out_tokens.append(tok.capitalize())

    return ' '.join(out_tokens).strip()


def extract_project_jsons(output_root):
    project_jsons = []
    for entry in os.listdir(output_root):
        entry_path = os.path.join(output_root, entry)
        if os.path.isdir(entry_path):
            # look for project_info json inside
            for fname in os.listdir(entry_path):
                if fname.endswith('_info_') or fname.endswith('.json') and 'info' in fname:
                    pass
            # more robust: find any json in this dir
            for dirpath, _, files in os.walk(entry_path):
                for f in files:
                    if f.endswith('.json') and 'info' in f or f.endswith('.json') and entry in f:
                        p = os.path.join(dirpath, f)
                        j = load_json(p)
                        if j:
                            project_jsons.append((entry, p, j))
        else:
            # top-level jsons (contributions lists)
            if entry.endswith('.json'):
                p = entry_path
                j = load_json(p)
                if j:
                    project_jsons.append((entry, p, j))
    return project_jsons


def collect_projects(output_root=None):
    # output_root is ignored; data is loaded from the database
    return load_projects_for_generation()


def aggregate_for_user(username, projects, root_repo_jsons, selected_non_git=None):
    selected_non_git = selected_non_git or []

    user_projects = []
    tech_set = set()
    skills_set = set()
    total_commits = 0
    total_lines = 0

   
    for name, info in projects.items():
        contribs = info.get("contributions") or {}

        # unwrap nested structure
        if isinstance(contribs, dict) and isinstance(contribs.get("contributions"), dict):
            contribs = contribs["contributions"]

        user_entry = contribs.get(username) if isinstance(contribs, dict) else None
        if not user_entry:
            continue

        pj = {
            "project_name": name,
            "path": info.get("project_path"),
            "languages": info.get("languages", []),
            "frameworks": info.get("frameworks", []),
            "skills": info.get("skills", []),
            "summary_text": info.get("summary_text"),
            "summary_model": info.get("summary_model"),
            "user_commits": user_entry.get("commits", 0),
            "user_files": user_entry.get("files", []),
            "git_metrics": info.get("git_metrics", {}),
        }

        user_projects.append(pj)
        tech_set.update(pj["languages"] or [])
        tech_set.update(pj["frameworks"] or [])
        skills_set.update(pj["skills"] or [])
        total_commits += pj["user_commits"] or 0

        gm = pj.get("git_metrics") or {}
        laps = gm.get("lines_added_per_author", {})
        if isinstance(laps, dict):
            total_lines += laps.get(username, 0) or 0

    
    for _, j in (root_repo_jsons or {}).items():
        if not isinstance(j, dict):
            continue

        cpa = j.get("commits_per_author")
        if isinstance(cpa, dict) and username in cpa:
            total_commits = max(
                total_commits,
                sum(v for v in cpa.values() if isinstance(v, int)),
            )

        laps = j.get("lines_added_per_author")
        if isinstance(laps, dict) and username in laps:
            total_lines = max(total_lines, laps.get(username, 0) or 0)

   
    existing = {p["project_name"] for p in user_projects}

    for proj_name in selected_non_git:
        if proj_name in existing:
            continue

        info = projects.get(proj_name)
        if not isinstance(info, dict):
            continue

        pj = {
            "project_name": proj_name,
            "path": info.get("project_path"),
            "languages": info.get("languages", []),
            "frameworks": info.get("frameworks", []),
            "skills": info.get("skills", []),
            "summary_text": info.get("summary_text"),
            "summary_model": info.get("summary_model"),
            "user_commits": 0,
            "user_files": [],
            "git_metrics": info.get("git_metrics", {}),
        }

        user_projects.append(pj)
        tech_set.update(pj["languages"] or [])
        tech_set.update(pj["frameworks"] or [])
        skills_set.update(pj["skills"] or [])

    return {
        "username": username,
        "projects": sorted(
            user_projects,
            key=lambda x: x.get("git_metrics", {}).get("project_start") or "",
            reverse=True,
        ),
        "technologies": sorted(t for t in tech_set if t),
        "skills": sorted(s for s in skills_set if s),
        "total_commits": total_commits,
        "total_lines_added": total_lines,
    }


def _resolve_project_display_name(project_name: str, path: str = None) -> str:
    custom_name = get_project_display_name(project_name)
    base_name = custom_name or project_name
    normalized_name = normalize_project_name(base_name, path) or base_name
    return normalized_name


def _build_resume_llm_payload(agg: dict) -> dict:
    projects_payload = []
    for p in agg.get("projects") or []:
        display_name = _resolve_project_display_name(p.get("project_name"), p.get("path"))
        projects_payload.append({
            "name": display_name,
            "languages": p.get("languages") or [],
            "frameworks": p.get("frameworks") or [],
            "skills": p.get("skills") or [],
            "summary_text": p.get("summary_text"),
        })
    return {
        "username": agg.get("username"),
        "projects": projects_payload,
        "technologies": agg.get("technologies") or [],
        "skills": agg.get("skills") or [],
    }


def _ensure_all_projects_mentioned(summary_text: str, project_names: list) -> str:
    if not summary_text:
        return summary_text
    missing = []
    lowered = summary_text.lower()
    for name in project_names:
        if name and name.lower() not in lowered:
            missing.append(name)
    if not missing:
        return summary_text
    suffix = "Projects: " + ", ".join(missing) + "."
    joiner = " " if summary_text.endswith((".", "!", "?")) else " "
    return summary_text.rstrip() + joiner + suffix


def maybe_generate_resume_summary(agg: dict, use_llm: bool, model: str = DEFAULT_MODEL) -> str:
    if not use_llm:
        return ""
    try:
        payload = _build_resume_llm_payload(agg)
        project_names = [p.get("name") for p in payload.get("projects") or [] if p.get("name")]
        summary = generate_resume_summary_text(payload, model=model)
        if not summary:
            return ""
        return _ensure_all_projects_mentioned(summary, project_names)
    except Exception:
        return ""


def _bullets_from_project_summary(summary_text: str, project_name: str, max_lines: int = 2) -> list:
    if not summary_text:
        return []
    # Split into sentences and keep 1-2 concise lines from the summary.
    parts = [p.strip() for p in re.split(r'(?<=[.!?])\s+', summary_text.strip()) if p.strip()]
    if not parts:
        return []

    bullets = []
    for part in parts:
        line = part.strip()
        if line and not line.endswith(('.', '!', '?')):
            line += '.'
        bullets.append(line)
        if len(bullets) >= max_lines:
            break
    return bullets



def render_markdown(agg, generated_ts=None, llm_summary: str = None):
    username = agg['username']
    # generated_ts should be an ISO-like UTC timestamp string; if not provided, create one
    if generated_ts:
        date = generated_ts
    else:
        date = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    md = []
    md.append(f"# Resume — {username}")
    md.append('')
    # Summary: 2–3 line overview of projects + skills/tech
    summary_lines = []
    project_count = len(agg.get('projects') or [])
    if project_count:
        plural = "s" if project_count != 1 else ""
        summary_lines.append(f"Contributor to {project_count} software project{plural}, delivering features across collaborative codebases.")
    else:
        summary_lines.append("Contributor to multiple coding projects, delivering features across collaborative codebases.")

    techs = agg.get('technologies') or []
    skills = agg.get('skills') or []
    if techs:
        summary_lines.append("Built with " + ', '.join(techs[:6]) + ".")
    if skills:
        summary_lines.append("Skills include " + ', '.join(skills[:6]) + ".")

    if len(summary_lines) < 2:
        summary_lines.append("Hands-on experience with project delivery and team collaboration.")

    summary = llm_summary.strip() if llm_summary else '\n'.join(summary_lines[:3])
    md.append('## Summary')
    md.append('')
    md.append(summary)
    md.append('')

    md.append('## Technical Skills')
    md.append('')
    if agg['technologies']:
        md.append('- Languages & Tools: **' + '**, **'.join(agg['technologies']) + '**')
    else:
        md.append('- Languages & Tools: (no detected languages)')
    if agg['skills']:
        md.append('- Skills: ' + ', '.join(agg['skills']))
    md.append('')

    md.append('## Projects')
    md.append('')
    if not agg['projects']:
        md.append('- No project-specific contributions found for this user in the database.')
    for p in agg['projects']:
        name = p.get('project_name')

        normalized_name = _resolve_project_display_name(name, p.get('path'))

        line = f"**{normalized_name}**"

        languages = p.get('languages') or []
        frameworks = p.get('frameworks') or []
        skills = p.get('skills') or []
        commits = p.get('user_commits') or 0
        files = p.get('user_files') or []

        md.append(line)
        
        # generate 2-4 bullets similar to earlier style
        techs = ', '.join([t for t in (languages + frameworks) if t])
        bullets = []
        # Prefer a concise, project-specific summary line if available
        summary_bullets = _bullets_from_project_summary(
            p.get("summary_text"),
            normalized_name,
        )
        if summary_bullets:
            bullets.extend(summary_bullets)
        elif commits:
            bullets.append("Contributed features and fixes across the codebase in collaboration with the team.")
        if techs:
            bullets.append(f"Technologies: {techs}.")
        if skills:
            bullets.append(f"Skills demonstrated: {', '.join(skills)}.")
        
        # Evidence integration: Add optional impact bullet if user-provided evidence exists
        # This does NOT modify aggregation or ranking logic; it only appends to output.
        try:
            project_id = get_project_id_by_name(name)
            if project_id:
                evidence = get_evidence_for_project(project_id)
                impact_clause = format_evidence_for_resume(evidence, max_items=2)
                if impact_clause:
                    bullets.append(impact_clause)
        except Exception:
            # Gracefully skip evidence if DB not available or any error occurs
            pass
        
        for b in bullets:
            md.append(f"- {b}")
        md.append('')

    
    md.append('')
    md.append(f"_Generated (UTC): {date}_")
    return '\n'.join(md)


def main():
    parser = argparse.ArgumentParser(
        description="Generate resume Markdown from the database for a given username"
    )
    parser.add_argument("--username", "-u", required=False)
    parser.add_argument("--output-root", "-r", default="output")  # ignored (DB is used)
    parser.add_argument("--resume-dir", "-d", default="resumes")
    parser.add_argument("--allow-bots", action="store_true")
    parser.add_argument("--save-to-db", action="store_true")
    llm_group = parser.add_mutually_exclusive_group()
    llm_group.add_argument("--llm-summary", action="store_true", help="Use local LLM for resume summary")
    llm_group.add_argument("--no-llm-summary", action="store_true", help="Disable local LLM for resume summary")
    args = parser.parse_args()

    BLACKLIST = {"githubclassroombot", "Unknown"}

    projects, root_repo_jsons = collect_projects(args.output_root)

    username = args.username
    selected_non_git = []

    if username:
        username = username.strip()
        if not username:
            print("No username entered; aborting.")
            return 0
    else:
        username, selected_non_git = select_identity_from_projects(
            projects=projects,
            root_repo_jsons=root_repo_jsons,
            blacklist=BLACKLIST,
        )

        if username is None and not selected_non_git:
            print("Cancelled.")
            return 0

        if username is None:
            username = "local"



    if (not args.allow_bots) and username in BLACKLIST:
        print(f"Generation disabled for user '{username}'")
        return 1

    os.makedirs(args.resume_dir, exist_ok=True)

    config = load_config(default_config_path())
    use_llm = None
    if args.llm_summary:
        use_llm = True
    elif args.no_llm_summary:
        use_llm = False
    else:
        noninteractive = os.environ.get('SCANNER_NONINTERACTIVE', '').lower() in ('1', 'true') or not sys.stdin.isatty()
        if noninteractive:
            use_llm = bool(config.get("llm_resume_consent"))
        else:
            use_llm = ask_yes_no(
                "Allow local LLM resume summary generation (uses Ollama, reads project summaries if present)? (y/n): ",
                default=bool(config.get("llm_resume_consent")),
            )

    # (re)aggregate for the chosen username
    agg = aggregate_for_user(username, projects, root_repo_jsons, selected_non_git)
    # Use a single UTC timestamp for both content and filename
    ts_iso = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    ts_fname = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
    llm_summary = maybe_generate_resume_summary(agg, use_llm=use_llm)
    md = render_markdown(agg, generated_ts=ts_iso, llm_summary=llm_summary)

    out_path = os.path.join(args.resume_dir, f"resume_{username}_{ts_fname}.md")
    with open(out_path, 'w', encoding='utf-8') as fh:
        fh.write(md)

    if args.save_to_db:
        try:
            save_resume(username=username, resume_path=out_path, metadata=agg, generated_at=ts_iso)
            print(f"Resume saved to database for user '{username}'.")
        except sqlite3.OperationalError as e:
            print(f"Warning: failed to save resume to database (schema missing?): {e}")
        except Exception as e:
            print(f"Warning: failed to save resume to database: {e}")

    print(f"Resume written: {out_path}")
    return 0


if __name__ == '__main__':
    raise SystemExit(main())
