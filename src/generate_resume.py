#!/usr/bin/env python3
"""Generate a resume Markdown for a specified username from the database.

Usage:
  python3 src/generate_resume.py --username <github_username>

The script reads project data from the local database, aggregates project-level
facts, and writes `resumes/<username>_resume.md`.
"""
import argparse
import json
import os
import re
import sqlite3
from db import get_project_display_name, load_projects_for_generation
from cli_username_selection import (
    select_identity_from_projects,
    get_candidate_usernames,
)
from collections import defaultdict
from datetime import datetime
from textwrap import dedent
from db import save_resume
from project_evidence import get_project_id_by_name, get_evidence_for_project, format_evidence_for_resume




def find_json_and_txt(root):
    matches = []
    for dirpath, dirs, files in os.walk(root):
        for f in files:
            if f.endswith('.json') or f.endswith('.txt'):
                matches.append(os.path.join(dirpath, f))
    return matches


def load_json(path):
    try:
        with open(path, 'r', encoding='utf-8') as fh:
            return json.load(fh)
    except Exception:
        return None


# Common acronym mappings to preserve casing in normalized names
ACRONYMS = {
    'tcp': 'TCP',
    'udp': 'UDP',
    'api': 'API',
    'sql': 'SQL',
    'html': 'HTML',
    'css': 'CSS',
    'json': 'JSON',
    'js': 'JS',
    'r': 'R',
    'c#': 'C#',
    'c++': 'C++',
    'go': 'Go',
    'java': 'Java',
    'kotlin': 'Kotlin',
    'typescript': 'TypeScript',
    'django': 'Django',
    'fastapi': 'FastAPI',
    'flask': 'Flask'
}


def normalize_project_name(name, path=None):
    """Normalize project name for resume output.

    - Removes common autogenerated suffixes like `_info_YYYY...` or `_summary_...`
    - Replaces separators (-, _, ., /) with spaces
    - Capitalizes words while preserving known acronyms
    """
    if not name and path:
        name = os.path.basename(path)
    if not name:
        return ''

    s = str(name)
    # strip common autogenerated suffixes
    s = re.sub(r'(_info[_-].*|_summary[_-].*|_info.*|_summary.*)$', '', s, flags=re.IGNORECASE)
    # replace separators with spaces
    s = re.sub(r'[\._/]+', ' ', s)
    s = s.replace('-', ' ')
    s = s.replace('__', ' ')
    s = s.strip()

    tokens = s.split()
    out_tokens = []
    for tok in tokens:
        tl = tok.lower()
        if tl in ACRONYMS:
            out_tokens.append(ACRONYMS[tl])
        else:
            # preserve camelCase/TitleCase if present, else capitalize
            if re.search(r'[A-Z]', tok[1:]):
                out_tokens.append(tok)
            else:
                out_tokens.append(tok.capitalize())

    return ' '.join(out_tokens).strip()


def extract_project_jsons(output_root):
    project_jsons = []
    for entry in os.listdir(output_root):
        entry_path = os.path.join(output_root, entry)
        if os.path.isdir(entry_path):
            # look for project_info json inside
            for fname in os.listdir(entry_path):
                if fname.endswith('_info_') or fname.endswith('.json') and 'info' in fname:
                    pass
            # more robust: find any json in this dir
            for dirpath, _, files in os.walk(entry_path):
                for f in files:
                    if f.endswith('.json') and 'info' in f or f.endswith('.json') and entry in f:
                        p = os.path.join(dirpath, f)
                        j = load_json(p)
                        if j:
                            project_jsons.append((entry, p, j))
        else:
            # top-level jsons (contributions lists)
            if entry.endswith('.json'):
                p = entry_path
                j = load_json(p)
                if j:
                    project_jsons.append((entry, p, j))
    return project_jsons


def collect_projects(output_root=None):
    # output_root is ignored; data is loaded from the database
    return load_projects_for_generation()


def aggregate_for_user(username, projects, root_repo_jsons, selected_non_git=None):
    selected_non_git = selected_non_git or []

    user_projects = []
    tech_set = set()
    skills_set = set()
    total_commits = 0
    total_lines = 0

   
    for name, info in projects.items():
        contribs = info.get("contributions") or {}

        # unwrap nested structure
        if isinstance(contribs, dict) and isinstance(contribs.get("contributions"), dict):
            contribs = contribs["contributions"]

        user_entry = contribs.get(username) if isinstance(contribs, dict) else None
        if not user_entry:
            continue

        pj = {
            "project_name": name,
            "path": info.get("project_path"),
            "languages": info.get("languages", []),
            "frameworks": info.get("frameworks", []),
            "skills": info.get("skills", []),
            "user_commits": user_entry.get("commits", 0),
            "user_files": user_entry.get("files", []),
            "git_metrics": info.get("git_metrics", {}),
        }

        user_projects.append(pj)
        tech_set.update(pj["languages"] or [])
        tech_set.update(pj["frameworks"] or [])
        skills_set.update(pj["skills"] or [])
        total_commits += pj["user_commits"] or 0

        gm = pj.get("git_metrics") or {}
        laps = gm.get("lines_added_per_author", {})
        if isinstance(laps, dict):
            total_lines += laps.get(username, 0) or 0

    
    for _, j in (root_repo_jsons or {}).items():
        if not isinstance(j, dict):
            continue

        cpa = j.get("commits_per_author")
        if isinstance(cpa, dict) and username in cpa:
            total_commits = max(
                total_commits,
                sum(v for v in cpa.values() if isinstance(v, int)),
            )

        laps = j.get("lines_added_per_author")
        if isinstance(laps, dict) and username in laps:
            total_lines = max(total_lines, laps.get(username, 0) or 0)

   
    existing = {p["project_name"] for p in user_projects}

    for proj_name in selected_non_git:
        if proj_name in existing:
            continue

        info = projects.get(proj_name)
        if not isinstance(info, dict):
            continue

        pj = {
            "project_name": proj_name,
            "path": info.get("project_path"),
            "languages": info.get("languages", []),
            "frameworks": info.get("frameworks", []),
            "skills": info.get("skills", []),
            "user_commits": 0,
            "user_files": [],
            "git_metrics": info.get("git_metrics", {}),
        }

        user_projects.append(pj)
        tech_set.update(pj["languages"] or [])
        tech_set.update(pj["frameworks"] or [])
        skills_set.update(pj["skills"] or [])

    return {
        "username": username,
        "projects": sorted(
            user_projects,
            key=lambda x: x.get("git_metrics", {}).get("project_start") or "",
            reverse=True,
        ),
        "technologies": sorted(t for t in tech_set if t),
        "skills": sorted(s for s in skills_set if s),
        "total_commits": total_commits,
        "total_lines_added": total_lines,
    }



def render_markdown(agg, generated_ts=None):
    username = agg['username']
    # generated_ts should be an ISO-like UTC timestamp string; if not provided, create one
    if generated_ts:
        date = generated_ts
    else:
        date = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    md = []
    md.append(f"# Resume — {username}")
    md.append('')
    # Summary: 2–3 line overview of projects + skills/tech
    summary_lines = []
    project_count = len(agg.get('projects') or [])
    if project_count:
        plural = "s" if project_count != 1 else ""
        summary_lines.append(f"Contributor to {project_count} software project{plural}, delivering features across collaborative codebases.")
    else:
        summary_lines.append("Contributor to multiple coding projects, delivering features across collaborative codebases.")

    techs = agg.get('technologies') or []
    skills = agg.get('skills') or []
    if techs:
        summary_lines.append("Built with " + ', '.join(techs[:6]) + ".")
    if skills:
        summary_lines.append("Skills include " + ', '.join(skills[:6]) + ".")

    if len(summary_lines) < 2:
        summary_lines.append("Hands-on experience with project delivery and team collaboration.")

    summary = '\n'.join(summary_lines[:3])
    md.append('## Summary')
    md.append('')
    md.append(summary)
    md.append('')

    md.append('## Technical Skills')
    md.append('')
    if agg['technologies']:
        md.append('- Languages & Tools: **' + '**, **'.join(agg['technologies']) + '**')
    else:
        md.append('- Languages & Tools: (no detected languages)')
    if agg['skills']:
        md.append('- Skills: ' + ', '.join(agg['skills']))
    md.append('')

    md.append('## Projects')
    md.append('')
    if not agg['projects']:
        md.append('- No project-specific contributions found for this user in the database.')
    for p in agg['projects']:
        name = p.get('project_name')

        # 1) Grab custom display name from DB (if any)
        custom_name = get_project_display_name(name)

        # 2) Decide what to show on the resume
        base_name = custom_name or name
        normalized_name = normalize_project_name(base_name, p.get('path')) or base_name

        line = f"**{normalized_name}**"

        languages = p.get('languages') or []
        frameworks = p.get('frameworks') or []
        skills = p.get('skills') or []
        commits = p.get('user_commits') or 0
        files = p.get('user_files') or []

        md.append(line)
        
        # generate 2-4 bullets similar to earlier style
        techs = ', '.join([t for t in (languages + frameworks) if t])
        bullets = []
        if commits:
            bullets.append("Contributed features and fixes across the codebase in collaboration with the team.")
        if techs:
            bullets.append(f"Technologies: {techs}.")
        if skills:
            bullets.append(f"Skills demonstrated: {', '.join(skills)}.")
        
        # Evidence integration: Add optional impact bullet if user-provided evidence exists
        # This does NOT modify aggregation or ranking logic; it only appends to output.
        try:
            project_id = get_project_id_by_name(name)
            if project_id:
                evidence = get_evidence_for_project(project_id)
                impact_clause = format_evidence_for_resume(evidence, max_items=2)
                if impact_clause:
                    bullets.append(impact_clause)
        except Exception:
            # Gracefully skip evidence if DB not available or any error occurs
            pass
        
        for b in bullets:
            md.append(f"- {b}")
        md.append('')

    
    md.append('')
    md.append(f"_Generated (UTC): {date}_")
    return '\n'.join(md)


def main():
    parser = argparse.ArgumentParser(description='Generate resume Markdown from the database for a given username')
    parser.add_argument('--username', '-u', required=False, help='GitHub username (as found in output contributions). If omitted, the script will prompt.')
    parser.add_argument('--output-root', '-r', default='output', help='Deprecated: output folder path is ignored (DB is used)')
    # output-root retained for CLI compatibility but ignored (DB is used)
    parser.add_argument('--resume-dir', '-d', default='resumes', help='Directory to write generated resumes')
    parser.add_argument('--allow-bots', action='store_true', help='Allow generating resumes for known bot accounts (not recommended)')
    parser.add_argument('--save-to-db', action='store_true', help='Save generated resume metadata to the database')
    args = parser.parse_args()

    
    BLACKLIST = {'githubclassroombot', 'Unknown'}

    projects, root_repo_jsons = collect_projects(args.output_root)

    username = args.username
    selected_non_git = []

    if username:
        username = username.strip()
        if not username:
            print("No username entered; aborting.")
            return 0
    else:
        username, selected_non_git = select_identity_from_projects(
            projects=projects,
            root_repo_jsons=root_repo_jsons,
            blacklist=BLACKLIST,
        )

        if username is None and not selected_non_git:
            print("Cancelled.")
            return 0

        if username is None:
            username = "local"



        
    # Prevent generating resumes for blacklisted accounts unless explicitly allowed
    if username in BLACKLIST and not args.allow_bots:
        print(f"Generation disabled for user '{username}'. To override, re-run with --allow-bots.")
        return 1

    os.makedirs(args.resume_dir, exist_ok=True)

    # (re)aggregate for the chosen username
    agg = aggregate_for_user(username, projects, root_repo_jsons, selected_non_git)
    # Use a single UTC timestamp for both content and filename
    ts_iso = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    ts_fname = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
    md = render_markdown(agg, generated_ts=ts_iso)

    out_path = os.path.join(args.resume_dir, f"resume_{username}_{ts_fname}.md")
    with open(out_path, 'w', encoding='utf-8') as fh:
        fh.write(md)

    if args.save_to_db:
        try:
            save_resume(username=username, resume_path=out_path, metadata=agg, generated_at=ts_iso)
            print(f"Resume saved to database for user '{username}'.")
        except sqlite3.OperationalError as e:
            print(f"Warning: failed to save resume to database (schema missing?): {e}")
        except Exception as e:
            print(f"Warning: failed to save resume to database: {e}")

    print(f"Resume written: {out_path}")
    return 0


if __name__ == '__main__':
    raise SystemExit(main())
