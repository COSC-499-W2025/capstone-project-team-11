#!/usr/bin/env python3
"""Generate a resume Markdown for a specified username from the database.

Usage:
  python3 src/generate_resume.py --username <github_username>

The script reads project data from the local database, aggregates project-level
facts, and writes `resumes/<username>_resume.md`.
"""
import argparse
import json
import os
import re
import sqlite3
from db import get_project_display_name, load_projects_for_generation
from collections import defaultdict
from datetime import datetime
from textwrap import dedent
from db import save_resume
from project_evidence import get_project_id_by_name, get_evidence_for_project, format_evidence_for_resume


def find_json_and_txt(root):
    matches = []
    for dirpath, dirs, files in os.walk(root):
        for f in files:
            if f.endswith('.json') or f.endswith('.txt'):
                matches.append(os.path.join(dirpath, f))
    return matches


def load_json(path):
    try:
        with open(path, 'r', encoding='utf-8') as fh:
            return json.load(fh)
    except Exception:
        return None


# Common acronym mappings to preserve casing in normalized names
ACRONYMS = {
    'tcp': 'TCP',
    'udp': 'UDP',
    'api': 'API',
    'sql': 'SQL',
    'html': 'HTML',
    'css': 'CSS',
    'json': 'JSON',
    'js': 'JS',
    'r': 'R',
    'c#': 'C#',
    'c++': 'C++',
    'go': 'Go',
    'java': 'Java',
    'kotlin': 'Kotlin',
    'typescript': 'TypeScript',
    'django': 'Django',
    'fastapi': 'FastAPI',
    'flask': 'Flask'
}


def normalize_project_name(name, path=None):
    """Normalize project name for resume output.

    - Removes common autogenerated suffixes like `_info_YYYY...` or `_summary_...`
    - Replaces separators (-, _, ., /) with spaces
    - Capitalizes words while preserving known acronyms
    """
    if not name and path:
        name = os.path.basename(path)
    if not name:
        return ''

    s = str(name)
    # strip common autogenerated suffixes
    s = re.sub(r'(_info[_-].*|_summary[_-].*|_info.*|_summary.*)$', '', s, flags=re.IGNORECASE)
    # replace separators with spaces
    s = re.sub(r'[\._/]+', ' ', s)
    s = s.replace('-', ' ')
    s = s.replace('__', ' ')
    s = s.strip()

    tokens = s.split()
    out_tokens = []
    for tok in tokens:
        tl = tok.lower()
        if tl in ACRONYMS:
            out_tokens.append(ACRONYMS[tl])
        else:
            # preserve camelCase/TitleCase if present, else capitalize
            if re.search(r'[A-Z]', tok[1:]):
                out_tokens.append(tok)
            else:
                out_tokens.append(tok.capitalize())

    return ' '.join(out_tokens).strip()


def extract_project_jsons(output_root):
    project_jsons = []
    for entry in os.listdir(output_root):
        entry_path = os.path.join(output_root, entry)
        if os.path.isdir(entry_path):
            # look for project_info json inside
            for fname in os.listdir(entry_path):
                if fname.endswith('_info_') or fname.endswith('.json') and 'info' in fname:
                    pass
            # more robust: find any json in this dir
            for dirpath, _, files in os.walk(entry_path):
                for f in files:
                    if f.endswith('.json') and 'info' in f or f.endswith('.json') and entry in f:
                        p = os.path.join(dirpath, f)
                        j = load_json(p)
                        if j:
                            project_jsons.append((entry, p, j))
        else:
            # top-level jsons (contributions lists)
            if entry.endswith('.json'):
                p = entry_path
                j = load_json(p)
                if j:
                    project_jsons.append((entry, p, j))
    return project_jsons


def collect_projects(output_root=None):
    # output_root is ignored; data is loaded from the database
    return load_projects_for_generation()


def aggregate_for_user(username, projects, root_repo_jsons):
    user_projects = []
    tech_set = set()
    skills_set = set()
    total_commits = 0
    total_lines = 0

    # project-level
    for name, info in projects.items():
        contribs = info.get('contributions', {}) or {}
        user_entry = contribs.get(username)
        if user_entry:
            pj = {
                'project_name': name,
                'path': info.get('project_path'),
                'languages': info.get('languages', []),
                'frameworks': info.get('frameworks', []),
                'skills': info.get('skills', []),
                'user_commits': user_entry.get('commits', 0),
                'user_files': user_entry.get('files', []),
                'git_metrics': info.get('git_metrics', {})
            }
            user_projects.append(pj)
            tech_set.update(pj['languages'] or [])
            tech_set.update(pj['frameworks'] or [])
            skills_set.update(pj['skills'] or [])
            total_commits += pj['user_commits'] or 0
            # try lines added per author if available
            gm = pj.get('git_metrics') or {}
            laps = gm.get('lines_added_per_author', {})
            if isinstance(laps, dict):
                la = laps.get(username) or 0
                total_lines += la

    # root repo-level contributions (fallback / aggregate)
    for fname, j in root_repo_jsons.items():
        # some of these are overall contributions maps listing authors
        if isinstance(j, dict):
            # look for commits per author
            cpa = j.get('commits_per_author') or j.get('commits_per_author')
            if isinstance(cpa, dict) and username in cpa:
                total_commits = max(total_commits, sum(v for v in cpa.values() if isinstance(v, int)))
            # lines added at repo-level
            laps = j.get('lines_added_per_author') or {}
            if isinstance(laps, dict) and username in laps:
                total_lines = max(total_lines, laps.get(username) or total_lines)

    aggregated = {
        'username': username,
        'projects': sorted(user_projects, key=lambda x: x.get('git_metrics', {}).get('project_start') or '', reverse=True),
        'technologies': sorted([t for t in tech_set if t]),
        'skills': sorted([s for s in skills_set if s]),
        'total_commits': total_commits,
        'total_lines_added': total_lines,
    }
    return aggregated


def render_markdown(agg, generated_ts=None):
    username = agg['username']
    # generated_ts should be an ISO-like UTC timestamp string; if not provided, create one
    if generated_ts:
        date = generated_ts
    else:
        date = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    md = []
    md.append(f"# Resume — {username}")
    md.append('')
    # Summary: conservative synthesis
    summary_lines = []
    if agg['skills']:
        summary_lines.append(', '.join(agg['skills']))
    if agg['technologies']:
        summary_lines.append('Experience with: ' + ', '.join(agg['technologies']))
    summary = ' · '.join(summary_lines) if summary_lines else 'Contributed to multiple coding and data-analysis projects.'
    md.append('## Summary')
    md.append('')
    md.append(summary)
    md.append('')

    md.append('## Technical Skills')
    md.append('')
    if agg['technologies']:
        md.append('- Languages & Tools: **' + '**, **'.join(agg['technologies']) + '**')
    else:
        md.append('- Languages & Tools: (no detected languages)')
    if agg['skills']:
        md.append('- Skills: ' + ', '.join(agg['skills']))
    md.append('')

    md.append('## Projects')
    md.append('')
    if not agg['projects']:
        md.append('- No project-specific contributions found for this user in the database.')
    for p in agg['projects']:
        name = p.get('project_name')

        # 1) Grab custom display name from DB (if any)
        custom_name = get_project_display_name(name)

        # 2) Decide what to show on the resume
        base_name = custom_name or name
        normalized_name = normalize_project_name(base_name, p.get('path')) or base_name

        line = f"**{normalized_name}**"

        languages = p.get('languages') or []
        frameworks = p.get('frameworks') or []
        skills = p.get('skills') or []
        commits = p.get('user_commits') or 0
        files = p.get('user_files') or []

        md.append(line)
        if p.get('path'):
            md.append(f"- Path: `{p.get('path')}`")
        # generate 2-4 bullets similar to earlier style
        techs = ', '.join([t for t in (languages + frameworks) if t])
        bullets = []
        if commits:
            bullets.append(f"Implemented features and fixes across the codebase ({commits} commits); files changed: {len(files)}.")
        if techs:
            bullets.append(f"Technologies: {techs}.")
        if skills:
            bullets.append(f"Skills demonstrated: {', '.join(skills)}.")
        
        # Evidence integration: Add optional impact bullet if user-provided evidence exists
        # This does NOT modify aggregation or ranking logic; it only appends to output.
        try:
            project_id = get_project_id_by_name(name)
            if project_id:
                evidence = get_evidence_for_project(project_id)
                impact_clause = format_evidence_for_resume(evidence, max_items=2)
                if impact_clause:
                    bullets.append(impact_clause)
        except Exception:
            # Gracefully skip evidence if DB not available or any error occurs
            pass
        
        for b in bullets:
            md.append(f"- {b}")
        md.append('')

    md.append('## Evidence & Metrics')
    md.append('')
    md.append(f"- Total commits (detected): {agg.get('total_commits', 0)}")
    md.append(f"- Total lines added (detected): {agg.get('total_lines_added', 0)}")
    md.append('')
    md.append(f"_Generated (UTC): {date}_")
    return '\n'.join(md)


def main():
    parser = argparse.ArgumentParser(description='Generate resume Markdown from the database for a given username')
    parser.add_argument('--username', '-u', required=False, help='GitHub username (as found in output contributions). If omitted, the script will prompt.')
    parser.add_argument('--output-root', '-r', default='output', help='Deprecated: output folder path is ignored (DB is used)')
    # output-root retained for CLI compatibility but ignored (DB is used)
    parser.add_argument('--resume-dir', '-d', default='resumes', help='Directory to write generated resumes')
    parser.add_argument('--allow-bots', action='store_true', help='Allow generating resumes for known bot accounts (not recommended)')
    parser.add_argument('--save-to-db', action='store_true', help='Save generated resume metadata to the database')
    args = parser.parse_args()

    # output_root is retained for CLI compatibility but is no longer used

    # Blacklist of usernames to avoid suggesting or generating resumes for
    BLACKLIST = {'githubclassroombot', 'Unknown'}

    # If username not provided, attempt to list detected usernames and prompt the user
    username = args.username
    projects, root_repo_jsons = collect_projects(args.output_root)
    
    if not username:
        # Discover possible usernames from project contributions
        candidates = set()
        for info in projects.values():
            contribs = info.get('contributions') or {}
            # Handle nested contributions structure
            if isinstance(contribs.get('contributions'), dict):
                contribs = contribs['contributions']
            candidates.update(contribs.keys())
        candidates = sorted([c for c in candidates if c not in BLACKLIST])

        if not candidates:
            print('No candidate usernames detected in the database.')
            try:
                user_in = input('Enter username to generate resume for: ').strip()
            except EOFError:
                print('No username provided and input not available.')
                return 1
            if not user_in:
                print('No username entered; aborting.')
                return 1
            username = user_in
        else:
            # Print a clean numbered list of candidates for the user to choose from
            print('\nDetected candidate usernames:')
            for i, c in enumerate(candidates, start=1):
                print(f"  {i}. {c}")
            print('\nYou may enter the number (e.g. 1) or the exact username.')
            try:
                user_in = input('Select username (number or name, leave blank to abort): ').strip()
            except EOFError:
                print('No username provided and input not available.')
                return 1
            if not user_in:
                print('No username entered; aborting.')
                return 1
            # If the user entered a number, map it to the username
            if user_in.isdigit():
                idx = int(user_in) - 1
                if 0 <= idx < len(candidates):
                    username = candidates[idx]
                else:
                    print('Selection out of range; aborting.')
                    return 1
            else:
                username = user_in
    else:
        username = username.strip()

    # Prevent generating resumes for blacklisted accounts unless explicitly allowed
    if username in BLACKLIST and not args.allow_bots:
        print(f"Generation disabled for user '{username}'. To override, re-run with --allow-bots.")
        return 1

    os.makedirs(args.resume_dir, exist_ok=True)

    # (re)aggregate for the chosen username
    agg = aggregate_for_user(username, projects, root_repo_jsons)
    # Use a single UTC timestamp for both content and filename
    ts_iso = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%SZ')
    ts_fname = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
    md = render_markdown(agg, generated_ts=ts_iso)

    out_path = os.path.join(args.resume_dir, f"resume_{username}_{ts_fname}.md")
    with open(out_path, 'w', encoding='utf-8') as fh:
        fh.write(md)

    if args.save_to_db:
        try:
            save_resume(username=username, resume_path=out_path, metadata=agg, generated_at=ts_iso)
            print(f"Resume saved to database for user '{username}'.")
        except sqlite3.OperationalError as e:
            print(f"Warning: failed to save resume to database (schema missing?): {e}")
        except Exception as e:
            print(f"Warning: failed to save resume to database: {e}")

    print(f"Resume written: {out_path}")
    return 0


if __name__ == '__main__':
    raise SystemExit(main())
